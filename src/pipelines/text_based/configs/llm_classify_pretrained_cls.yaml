name: "llm_classify_pretrained_cls"

experiment:
  mode: "pretrained_cls"  # Load continued-pretrained checkpoint, train classifier head only
  notes: >
    Run this after `llm_pretrain2.py` finishes. Point `model.pretrained_checkpoint`
    at the saved `final_subdir` (defaults to `final_model`) produced in the pretraining job.

model:
  unsloth_model: "unsloth/Qwen3-8B-Base-unsloth-bnb-4bit"
  pretrained_checkpoint: "/data/scratch/qc25022/pancreas/experiments/Pretrain-Qwen3-8B-Pancreas/checkpoint-19650"
  hidden_size: 4096
  num_labels: 2
  freeze_llm: true
  train_lora: false  # Keep LoRA adapters frozen, classifier-only finetune

wandb:
  enabled: true
  project: "Pretrain-Qwen3-8B-Pancreas-classification-logisitc"
  run_name: "frozen-LoRA-6-month"

training:
  output_dir: "/data/scratch/qc25022/pancreas/experiments/frozen-LoRA-6-month"
  overwrite_output_dir: true
  epochs: 1
  batch_size: 4
  eval_batch_size: 4
  learning_rate: 1e-6
  weight_decay: 0.01
  warmup_steps: 100
  gradient_accumulation_steps: 2
  fp16: false
  bf16: true
  logging_steps: 50
  eval_steps: 250
  save_steps: 500
  save_total_limit: 2
  load_in_4bit: true
  multi_label: false
  # early_stopping_patience: 5
  # early_stopping_threshold: 0.001

data:
  cutoff_months: 6
  data_dir: "/data/scratch/qc25022/pancreas/tokenised_data_word_level/cprd_upgi/"
  vocab_filepath: "/data/scratch/qc25022/pancreas/tokenised_data_word_level/cprd_upgi/vocab.csv"
  labels_filepath: "/data/scratch/qc25022/upgi/master_subject_labels.csv"
  medical_lookup_filepath: "/data/home/qc25022/CancEHR-Training/src/resources/MedicalDictTranslation2.csv"
  lab_lookup_filepath: "/data/home/qc25022/CancEHR-Training/src/resources/LabLookUP.csv"
  region_lookup_filepath: "/data/home/qc25022/CancEHR-Training/src/resources/RegionLookUp.csv"
  time_lookup_filepath: "/data/home/qc25022/CancEHR-Training/src/resources/TimeLookUp.csv"
  max_length: 12000

